{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac4ccfc",
   "metadata": {},
   "source": [
    "# Vietnamese GEC with Contrastive Learning - Complete Pipeline\n",
    "\n",
    "This notebook implements the complete pipeline for training Vietnamese Grammatical Error Correction models with Contrastive Learning as described in the research paper.\n",
    "\n",
    "## Pipeline Overview:\n",
    "1. **Data Preparation** - Load and preprocess viGEC dataset\n",
    "2. **Base Model Training** - Fine-tune BARTpho/ViT5 with hyperparameter optimization\n",
    "3. **Negative Sample Generation** - Generate negative samples for contrastive learning\n",
    "4. **Contrastive Learning Training** - Train with contrastive loss + R-Drop\n",
    "5. **Inference** - Use contrastive search for generation\n",
    "6. **Evaluation** - Comprehensive evaluation with F0.5, BLEU, IE/OE analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e46c94",
   "metadata": {},
   "source": [
    "## üöÄ Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c159bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install transformers==4.36.0 datasets==2.15.0 accelerate==0.25.0\n",
    "!pip install optuna==3.4.0 wandb==0.16.0 lightning==2.1.0\n",
    "!pip install sentencepiece tokenizers nltk sacrebleu evaluate rouge-score\n",
    "!pip install pandas numpy scikit-learn tqdm rich omegaconf hydra-core\n",
    "!pip install underthesea pyvi ipywidgets matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (if needed)\n",
    "# !git clone https://github.com/your-repo/CL_GEC.git\n",
    "# %cd CL_GEC\n",
    "\n",
    "# Or upload files directly to Colab\n",
    "import os\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "os.makedirs('./evaluation_results', exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Directories created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f33240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload all Python files to Colab\n",
    "# Use the file upload button in Colab to upload:\n",
    "# - data_utils.py\n",
    "# - base_trainer.py  \n",
    "# - negative_sampler.py\n",
    "# - contrastive_trainer.py\n",
    "# - inference.py\n",
    "# - evaluator.py\n",
    "# - evaluate_model.py\n",
    "\n",
    "# Verify files are uploaded\n",
    "required_files = [\n",
    "    'data_utils.py', 'base_trainer.py', 'negative_sampler.py',\n",
    "    'contrastive_trainer.py', 'inference.py', 'evaluator.py', 'evaluate_model.py'\n",
    "]\n",
    "\n",
    "for file in required_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"‚úÖ {file} found\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file} missing - please upload this file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e002faf",
   "metadata": {},
   "source": [
    "## üìä Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import torch\n",
    "import wandb\n",
    "from rich.console import Console\n",
    "from data_utils import load_vigec_dataset, save_processed_data, get_model_and_tokenizer\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "console.print(f\"üî• Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    console.print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    console.print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to wandb for experiment tracking\n",
    "!wandb login\n",
    "\n",
    "# Set wandb project\n",
    "wandb.login()\n",
    "console.print(\"üìà Wandb setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42649c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess viGEC dataset\n",
    "console.print(\"üì• Loading viGEC dataset...\")\n",
    "\n",
    "# Load the dataset\n",
    "data = load_vigec_dataset(dataset_name=\"phuhuy-se1/viGEC\")\n",
    "\n",
    "# Save processed data\n",
    "save_processed_data(data, \"./data/processed\")\n",
    "\n",
    "console.print(f\"‚úÖ Data preprocessing completed!\")\n",
    "for split, split_data in data.items():\n",
    "    console.print(f\"  {split}: {len(split_data)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76fffde",
   "metadata": {},
   "source": [
    "## üéØ Step 2: Base Model Training with Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your base model\n",
    "# Options: \"vinai/bartpho-syllable\", \"vinai/bartpho-word\", \"VietAI/vit5-base\", \"VietAI/vit5-large\"\n",
    "\n",
    "MODEL_NAME = \"vinai/bartpho-syllable\"  # Change this as needed\n",
    "\n",
    "console.print(f\"ü§ñ Selected model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_trainer import BaseTrainer\n",
    "\n",
    "# Create base trainer\n",
    "base_trainer = BaseTrainer(\n",
    "    model_name=MODEL_NAME,\n",
    "    data_dir=\"./data/processed\",\n",
    "    output_dir=\"./models/base\",\n",
    "    hyperopt=True  # Set to False to skip hyperparameter optimization\n",
    ")\n",
    "\n",
    "console.print(\"üèóÔ∏è Base trainer initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start base model training\n",
    "# This will:\n",
    "# 1. Run hyperparameter optimization (30 trials)\n",
    "# 2. Train final model with best parameters\n",
    "# 3. Save model and tokenizer\n",
    "\n",
    "console.print(\"üöÄ Starting base model training...\")\n",
    "console.print(\"‚è∞ This may take 2-4 hours depending on your setup\")\n",
    "\n",
    "base_trainer.train()\n",
    "\n",
    "console.print(\"‚úÖ Base model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddcdc01",
   "metadata": {},
   "source": [
    "## üé≠ Step 3: Negative Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from negative_sampler import NegativeSampleGenerator\n",
    "\n",
    "# Create negative sample generator using the trained base model\n",
    "BASE_MODEL_PATH = \"./models/base/final\"\n",
    "\n",
    "console.print(\"üé≠ Initializing negative sample generator...\")\n",
    "\n",
    "generator = NegativeSampleGenerator(\n",
    "    model_path=BASE_MODEL_PATH,\n",
    "    device=\"auto\"\n",
    ")\n",
    "\n",
    "console.print(\"‚úÖ Negative sample generator ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import load_processed_data\n",
    "import os\n",
    "\n",
    "# Load processed data\n",
    "data = load_processed_data(\"./data/processed\")\n",
    "\n",
    "# Generate contrastive datasets\n",
    "os.makedirs(\"./data/contrastive\", exist_ok=True)\n",
    "\n",
    "console.print(\"üîÑ Generating negative samples...\")\n",
    "console.print(\"‚è∞ This may take 1-2 hours depending on dataset size\")\n",
    "\n",
    "for split in ['train', 'validation']:\n",
    "    if split in data:\n",
    "        console.print(f\"Processing {split} split...\")\n",
    "        \n",
    "        output_path = f\"./data/contrastive/{split}_contrastive.json\"\n",
    "        \n",
    "        contrastive_data = generator.generate_contrastive_dataset(\n",
    "            data[split],\n",
    "            output_path,\n",
    "            batch_size=8,\n",
    "            max_samples=None  # Set to smaller number for testing, e.g., 1000\n",
    "        )\n",
    "        \n",
    "        # Analyze quality\n",
    "        generator.analyze_negatives_quality(contrastive_data, sample_size=5)\n",
    "\n",
    "console.print(\"‚úÖ Negative sample generation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6054d04",
   "metadata": {},
   "source": [
    "## üîÑ Step 4: Contrastive Learning Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a6f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastive_trainer import ContrastiveTrainer\n",
    "\n",
    "# Create contrastive trainer\n",
    "contrastive_trainer = ContrastiveTrainer(\n",
    "    base_model_path=BASE_MODEL_PATH,\n",
    "    contrastive_data_dir=\"./data/contrastive\",\n",
    "    output_dir=\"./models/contrastive\",\n",
    "    hyperopt=True  # Set to False to skip hyperparameter optimization\n",
    ")\n",
    "\n",
    "console.print(\"üîÑ Contrastive trainer initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start contrastive learning training\n",
    "# This will:\n",
    "# 1. Run hyperparameter optimization for Œª, Œ≥, k\n",
    "# 2. Train final model with contrastive loss + R-Drop\n",
    "# 3. Save final contrastive model\n",
    "\n",
    "console.print(\"üöÄ Starting contrastive learning training...\")\n",
    "console.print(\"‚è∞ This may take 1-3 hours\")\n",
    "\n",
    "contrastive_trainer.train()\n",
    "\n",
    "console.print(\"‚úÖ Contrastive learning training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc86a8",
   "metadata": {},
   "source": [
    "## üîÆ Step 5: Inference with Contrastive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b70eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import GECInference\n",
    "\n",
    "# Load the trained contrastive model\n",
    "CONTRASTIVE_MODEL_PATH = \"./models/contrastive/final\"\n",
    "\n",
    "# Create inference engines\n",
    "console.print(\"üîÆ Initializing inference engines...\")\n",
    "\n",
    "# Contrastive search inference\n",
    "contrastive_inference = GECInference(\n",
    "    model_path=CONTRASTIVE_MODEL_PATH,\n",
    "    use_contrastive_search=True,\n",
    "    contrastive_alpha=0.7,\n",
    "    contrastive_k=5\n",
    ")\n",
    "\n",
    "# Beam search inference for comparison\n",
    "beam_inference = GECInference(\n",
    "    model_path=CONTRASTIVE_MODEL_PATH,\n",
    "    use_contrastive_search=False\n",
    ")\n",
    "\n",
    "console.print(\"‚úÖ Inference engines ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f028e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference with sample texts\n",
    "test_texts = [\n",
    "    \"T√¥i ƒëi h·ªçc tr∆∞·ªùng ƒë·∫°i h·ªçc.\",\n",
    "    \"H√¥m nay t√¥i kh√¥ng ƒëi l√†m.\",\n",
    "    \"C√¥ ·∫•y r·∫•t ƒë·∫πp v√† th√¥ng minh.\",\n",
    "    \"Ch√∫ng t√¥i s·∫Ω ƒëi du l·ªãch v√†o tu·∫ßn t·ªõi.\",\n",
    "    \"Anh ·∫•y l√†m vi·ªác ·ªü c√¥ng ty l·ªõn.\"\n",
    "]\n",
    "\n",
    "console.print(\"üß™ Testing inference on sample texts...\")\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    console.print(f\"\\n[bold cyan]Example {i+1}:[/bold cyan]\")\n",
    "    console.print(f\"[yellow]Original:[/yellow] {text}\")\n",
    "    \n",
    "    # Contrastive search\n",
    "    contrastive_result = contrastive_inference.correct_text(text)\n",
    "    console.print(f\"[green]Contrastive:[/green] {contrastive_result}\")\n",
    "    \n",
    "    # Beam search\n",
    "    beam_result = beam_inference.correct_text(text)\n",
    "    console.print(f\"[blue]Beam:[/blue] {beam_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f2ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive correction (optional)\n",
    "# Uncomment to enable interactive mode\n",
    "\n",
    "# console.print(\"üéÆ Interactive mode - Enter text to correct (type 'quit' to exit):\")\n",
    "# contrastive_inference.interactive_correction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f1867",
   "metadata": {},
   "source": [
    "## üìä Step 6: Comprehensive Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d018b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_model import ModelEvaluator\n",
    "\n",
    "# Create model evaluator\n",
    "evaluator = ModelEvaluator(\n",
    "    model_path=CONTRASTIVE_MODEL_PATH,\n",
    "    data_dir=\"./data/processed\",\n",
    "    output_dir=\"./evaluation_results\"\n",
    ")\n",
    "\n",
    "console.print(\"üìä Model evaluator initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive evaluation\n",
    "console.print(\"üîç Starting comprehensive evaluation...\")\n",
    "console.print(\"‚è∞ This may take 30-60 minutes\")\n",
    "\n",
    "# Evaluate on test set with different decoding strategies\n",
    "evaluation_results = evaluator.evaluate_on_test_set(\n",
    "    max_samples=None,  # Set to smaller number for testing, e.g., 500\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "console.print(\"‚úÖ Evaluation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error type analysis\n",
    "console.print(\"üî¨ Running error type analysis...\")\n",
    "\n",
    "error_analysis = evaluator.evaluate_error_types(\n",
    "    max_samples=1000  # Limit for faster analysis\n",
    ")\n",
    "\n",
    "console.print(\"‚úÖ Error type analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fabe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evaluation visualizations\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "# Show evaluation comparison plot\n",
    "plot_path = \"./evaluation_results/evaluation_comparison.png\"\n",
    "if os.path.exists(plot_path):\n",
    "    console.print(\"üìà Evaluation Comparison Visualization:\")\n",
    "    display(Image(plot_path))\n",
    "else:\n",
    "    console.print(\"‚ùå Visualization not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show evaluation results summary\n",
    "import pandas as pd\n",
    "\n",
    "# Load and display comparison table\n",
    "csv_path = \"./evaluation_results/strategy_comparison.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    console.print(\"üìã Strategy Comparison Results:\")\n",
    "    display(df)\n",
    "else:\n",
    "    console.print(\"‚ùå Comparison table not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797276b8",
   "metadata": {},
   "source": [
    "## üìÅ Results and Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432def41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of trained models and results\n",
    "console.print(\"\\n[bold green]üéâ Training Pipeline Completed Successfully![/bold green]\")\n",
    "\n",
    "console.print(\"\\nüìÅ [bold]Generated Models and Results:[/bold]\")\n",
    "console.print(f\"  üì¶ Base Model: ./models/base/final\")\n",
    "console.print(f\"  üîÑ Contrastive Model: ./models/contrastive/final\")\n",
    "console.print(f\"  üìä Evaluation Results: ./evaluation_results/\")\n",
    "console.print(f\"  üé≠ Contrastive Data: ./data/contrastive/\")\n",
    "\n",
    "# List all generated files\n",
    "import os\n",
    "\n",
    "def list_files_recursive(directory):\n",
    "    files = []\n",
    "    for root, dirs, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            files.append(os.path.join(root, filename))\n",
    "    return files\n",
    "\n",
    "console.print(\"\\nüìã [bold]All Generated Files:[/bold]\")\n",
    "\n",
    "for directory in ['./models', './evaluation_results', './data/contrastive']:\n",
    "    if os.path.exists(directory):\n",
    "        files = list_files_recursive(directory)\n",
    "        console.print(f\"\\n  üìÇ {directory}:\")\n",
    "        for file in files[:10]:  # Show first 10 files\n",
    "            console.print(f\"    üìÑ {file}\")\n",
    "        if len(files) > 10:\n",
    "            console.print(f\"    ... and {len(files) - 10} more files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db072f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download models and results (for local use)\n",
    "# Uncomment to create zip files for download\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# console.print(\"üì¶ Creating downloadable archives...\")\n",
    "\n",
    "# # Create zip files\n",
    "# shutil.make_archive('contrastive_gec_model', 'zip', './models/contrastive/final')\n",
    "# shutil.make_archive('evaluation_results', 'zip', './evaluation_results')\n",
    "\n",
    "# console.print(\"‚úÖ Archives created:\")\n",
    "# console.print(\"  üì¶ contrastive_gec_model.zip - Trained model\")\n",
    "# console.print(\"  üì¶ evaluation_results.zip - Evaluation results\")\n",
    "# console.print(\"\\nüíæ Use the file browser to download these files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab3d72",
   "metadata": {},
   "source": [
    "## üöÄ Quick Usage Guide\n",
    "\n",
    "Once training is complete, you can use the model for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick usage example\n",
    "console.print(\"üöÄ [bold]Quick Usage Example:[/bold]\")\n",
    "\n",
    "# Load the model\n",
    "from inference import GECInference\n",
    "\n",
    "# Initialize\n",
    "gec_model = GECInference(\n",
    "    model_path=\"./models/contrastive/final\",\n",
    "    use_contrastive_search=True\n",
    ")\n",
    "\n",
    "# Correct text\n",
    "text = \"T√¥i ƒëi h·ªçc tr∆∞·ªùng ƒë·∫°i h·ªçc.\"\n",
    "corrected = gec_model.correct_text(text)\n",
    "\n",
    "console.print(f\"Original: {text}\")\n",
    "console.print(f\"Corrected: {corrected}\")\n",
    "\n",
    "console.print(\"\\nüí° [bold]Usage Tips:[/bold]\")\n",
    "console.print(\"  üéØ Use contrastive_search=True for better quality\")\n",
    "console.print(\"  ‚ö° Use contrastive_search=False for faster inference\")\n",
    "console.print(\"  üìä Adjust alpha and k parameters for fine-tuning\")\n",
    "console.print(\"  üìÅ Process files with correct_file() method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d2fae",
   "metadata": {},
   "source": [
    "## üìù Configuration and Hyperparameters\n",
    "\n",
    "Key hyperparameters used in this pipeline:\n",
    "\n",
    "### Base Training:\n",
    "- **Learning Rate**: Optimized via Optuna (typically 1e-5 to 1e-4)\n",
    "- **Label Smoothing**: 0.1\n",
    "- **Batch Size**: 8-32 (depending on GPU memory)\n",
    "- **Max Length**: 384 tokens\n",
    "- **Epochs**: 5-10\n",
    "\n",
    "### Contrastive Learning:\n",
    "- **Œª (lambda_cl)**: 1.0 (balance between CE and CL loss)\n",
    "- **Œ≥ (temperature)**: 0.25 (contrastive loss temperature)\n",
    "- **R-Drop Œ±**: 4.0 (R-Drop regularization strength)\n",
    "- **Epochs**: 3-5\n",
    "\n",
    "### Contrastive Search:\n",
    "- **Œ± (alpha)**: 0.7 (balance between confidence and diversity)\n",
    "- **k**: 5 (top-k candidates)\n",
    "- **Beam Size**: 1 (as recommended in paper)\n",
    "\n",
    "These parameters can be adjusted based on your specific needs and computational resources."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
