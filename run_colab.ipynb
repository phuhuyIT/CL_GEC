{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627bd662",
   "metadata": {},
   "source": [
    "# üáªüá≥ Vietnamese GEC with Contrastive Learning - Google Colab\n",
    "\n",
    "**Clean & Simple**: Clone repository and run training pipeline for Vietnamese Grammatical Error Correction with BARTpho/ViT5 + Contrastive Learning.\n",
    "\n",
    "## üìã Pipeline Overview:\n",
    "1. **Setup & Clone Repository** - Install dependencies and clone source code\n",
    "2. **Data Preparation** - Load and preprocess viGEC dataset  \n",
    "3. **Base Model Training** - Fine-tune BARTpho/ViT5 with hyperparameter optimization\n",
    "4. **Negative Sample Generation** - Generate negative samples for contrastive learning\n",
    "5. **Contrastive Learning Training** - Train with contrastive loss + R-Drop\n",
    "6. **Inference & Evaluation** - Test and evaluate the model\n",
    "\n",
    "‚è∞ **Estimated Total Time**: 4-9 hours (depending on GPU)  \n",
    "üöÄ **Ready to Run**: All import issues fixed, clean codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e33c59",
   "metadata": {},
   "source": [
    "## üöÄ Step 1: Setup and Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f110603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"üî• CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU available - training will be very slow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5032aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "!pip install numpy\n",
    "!pip3 install torch torchaudio torchvision torchtext torchdata\n",
    "!pip install transformers datasets accelerate\n",
    "!pip install optuna  wandb lightning\n",
    "!pip install sentencepiece tokenizers nltk sacrebleu evaluate rouge-score\n",
    "!pip install pandas scikit-learn tqdm rich omegaconf hydra-core\n",
    "!pip install underthesea pyvi ipywidgets matplotlib seaborn\n",
    "!pip install -U datasets huggingface_hub fsspec\n",
    "!pip install optuna-integration[pytorch_lightning]\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac40a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (replace with your actual GitHub repository URL)\n",
    "import os\n",
    "\n",
    "# Change this to your actual repository URL\n",
    "REPO_URL = \"https://github.com/YOUR_USERNAME/CL_GEC.git\"  # Update this!\n",
    "PROJECT_DIR = \"/content/CL_GEC\"\n",
    "\n",
    "# Clone or update repository\n",
    "if not os.path.exists(PROJECT_DIR):\n",
    "    print(f\"üì• Cloning repository from {REPO_URL}...\")\n",
    "    !git clone {REPO_URL} {PROJECT_DIR}\n",
    "else:\n",
    "    print(\"üìÅ Repository already exists, pulling latest changes...\")\n",
    "    %cd {PROJECT_DIR}\n",
    "    !git pull\n",
    "\n",
    "# Change to project directory\n",
    "%cd {PROJECT_DIR}\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# List files to verify\n",
    "print(\"\\nüìã Project files:\")\n",
    "!ls -la *.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b671a",
   "metadata": {},
   "source": [
    "## üìä Step 2: Data Preparation and System Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c36e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports and system readiness\n",
    "from data_utils import (\n",
    "    load_vigec_dataset, \n",
    "    get_model_and_tokenizer, \n",
    "    can_train_base_model,\n",
    "    check_dataset_format\n",
    ")\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Check system readiness\n",
    "console.print(\"[bold blue]üîç System Readiness Check[/bold blue]\")\n",
    "system_ready = can_train_base_model()\n",
    "\n",
    "# Check dataset format\n",
    "console.print(\"\\n[bold blue]üìã Dataset Format Check[/bold blue]\")\n",
    "dataset_ready = check_dataset_format()\n",
    "\n",
    "if system_ready and dataset_ready:\n",
    "    console.print(\"\\n[bold green]‚úÖ All checks passed! Ready to proceed.[/bold green]\")\n",
    "else:\n",
    "    console.print(\"\\n[bold red]‚ùå System not ready. Please check requirements.[/bold red]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa031742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "console.print(\"[bold blue]üìä Loading viGEC Dataset[/bold blue]\")\n",
    "\n",
    "# Load dataset (using small subset for faster processing in Colab)\n",
    "data = load_vigec_dataset(\n",
    "    dataset_name=\"phuhuy-se1/viGEC\",\n",
    "    test_subset_ratio=0.05  # Use 5% of test set for faster evaluation\n",
    ")\n",
    "\n",
    "console.print(f\"\\n[green]Dataset loaded successfully![/green]\")\n",
    "for split, split_data in data.items():\n",
    "    console.print(f\"  {split}: {len(split_data)} samples\")\n",
    "\n",
    "# Save processed data\n",
    "from data_utils import save_processed_data\n",
    "save_processed_data(data, \"./data/processed\")\n",
    "console.print(\"\\n[blue]‚úÖ Data saved to ./data/processed/[/blue]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201dc15d",
   "metadata": {},
   "source": [
    "## ü§ñ Step 3: Model Selection and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your model - uncomment one of these:\n",
    "MODEL_NAME = \"vinai/bartpho-syllable\"  # Recommended for Vietnamese\n",
    "# MODEL_NAME = \"VietAI/vit5-base\"     # Alternative option\n",
    "# MODEL_NAME = \"VietAI/vit5-large\"    # Larger model (requires more GPU memory)\n",
    "\n",
    "console.print(f\"[bold blue]ü§ñ Loading Model: {MODEL_NAME}[/bold blue]\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model, tokenizer = get_model_and_tokenizer(MODEL_NAME)\n",
    "\n",
    "console.print(f\"[green]‚úÖ Model loaded successfully![/green]\")\n",
    "console.print(f\"  Model: {model.__class__.__name__}\")\n",
    "console.print(f\"  Tokenizer: {tokenizer.__class__.__name__}\")\n",
    "console.print(f\"  Vocabulary size: {len(tokenizer)}\")\n",
    "\n",
    "# Test tokenization\n",
    "test_text = \"T√¥i ƒëang h·ªçc ti·∫øng vi·ªát.\"\n",
    "tokens = tokenizer(test_text, return_tensors=\"pt\")\n",
    "console.print(f\"\\n[blue]üß™ Tokenization Test:[/blue]\")\n",
    "console.print(f\"  Input: {test_text}\")\n",
    "console.print(f\"  Tokens: {tokens['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39334726",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Step 4: Base Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214bb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training parameters\n",
    "TRAINING_CONFIG = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"output_dir\": \"./models/base_model\",\n",
    "    \"max_epochs\": 3,  # Reduced for Colab\n",
    "    \"batch_size\": 8,  # Adjust based on GPU memory\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"use_wandb\": True,  # Set to False if you don't want to use Weights & Biases\n",
    "    \"run_optimization\": False,  # Set to True for hyperparameter optimization (takes longer)\n",
    "}\n",
    "\n",
    "console.print(\"[bold blue]üèãÔ∏è Base Model Training Configuration:[/bold blue]\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    console.print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2820213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start base model training\n",
    "from base_trainer import BaseTrainer\n",
    "\n",
    "console.print(\"[bold green]üöÄ Starting Base Model Training...[/bold green]\")\n",
    "\n",
    "# Create base trainer\n",
    "base_trainer = BaseTrainer(\n",
    "    model_name=TRAINING_CONFIG[\"model_name\"],\n",
    "    output_dir=TRAINING_CONFIG[\"output_dir\"],\n",
    "    use_wandb=TRAINING_CONFIG[\"use_wandb\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "if TRAINING_CONFIG[\"run_optimization\"]:\n",
    "    console.print(\"[yellow]üîç Running hyperparameter optimization...[/yellow]\")\n",
    "    best_params = base_trainer.optimize_hyperparameters(\n",
    "        data=data,\n",
    "        n_trials=10,  # Reduced for Colab\n",
    "        timeout=3600  # 1 hour timeout\n",
    "    )\n",
    "    console.print(f\"[green]‚úÖ Best parameters: {best_params}[/green]\")\n",
    "else:\n",
    "    console.print(\"[blue]üèÉ Training with default parameters...[/blue]\")\n",
    "    base_trainer.train(\n",
    "        data=data,\n",
    "        max_epochs=TRAINING_CONFIG[\"max_epochs\"],\n",
    "        batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "        learning_rate=TRAINING_CONFIG[\"learning_rate\"]\n",
    "    )\n",
    "\n",
    "console.print(\"[bold green]‚úÖ Base model training completed![/bold green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d4aaa",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Negative Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bb095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate negative samples for contrastive learning\n",
    "from negative_sampler import NegativeSampler\n",
    "\n",
    "console.print(\"[bold blue]üéØ Generating Negative Samples...[/bold blue]\")\n",
    "\n",
    "# Create negative sampler\n",
    "negative_sampler = NegativeSampler(\n",
    "    model_path=TRAINING_CONFIG[\"output_dir\"],  # Use trained base model\n",
    "    model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "# Generate negative samples for training data\n",
    "contrastive_data = negative_sampler.generate_contrastive_dataset(\n",
    "    data=data['train'][:1000],  # Use subset for faster processing in Colab\n",
    "    num_negatives=3,  # Generate 3 negative samples per positive\n",
    "    output_file=\"./data/contrastive_train.json\"\n",
    ")\n",
    "\n",
    "console.print(f\"[green]‚úÖ Generated {len(contrastive_data)} contrastive samples![/green]\")\n",
    "console.print(\"[blue]üíæ Saved to ./data/contrastive_train.json[/blue]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622975a9",
   "metadata": {},
   "source": [
    "## üî• Step 6: Contrastive Learning Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f588ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive learning training\n",
    "from contrastive_trainer import ContrastiveTrainer\n",
    "\n",
    "console.print(\"[bold blue]üî• Starting Contrastive Learning Training...[/bold blue]\")\n",
    "\n",
    "# Create contrastive trainer\n",
    "contrastive_trainer = ContrastiveTrainer(\n",
    "    base_model_path=TRAINING_CONFIG[\"output_dir\"],\n",
    "    model_name=MODEL_NAME,\n",
    "    output_dir=\"./models/contrastive_model\",\n",
    "    use_wandb=TRAINING_CONFIG[\"use_wandb\"]\n",
    ")\n",
    "\n",
    "# Train with contrastive learning\n",
    "contrastive_trainer.train(\n",
    "    contrastive_data=contrastive_data,\n",
    "    validation_data=data['validation'][:200],  # Use subset for validation\n",
    "    max_epochs=2,  # Fewer epochs for contrastive learning\n",
    "    batch_size=4,  # Smaller batch size due to multiple samples per item\n",
    "    learning_rate=2e-5,  # Lower learning rate for fine-tuning\n",
    "    contrastive_weight=0.5,  # Weight for contrastive loss\n",
    "    rdrop_weight=0.1  # Weight for R-Drop regularization\n",
    ")\n",
    "\n",
    "console.print(\"[bold green]‚úÖ Contrastive learning training completed![/bold green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f940b5f",
   "metadata": {},
   "source": [
    "## üß™ Step 7: Inference and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539896fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model for inference\n",
    "from inference import GECInference\n",
    "\n",
    "console.print(\"[bold blue]üß™ Setting up Inference...[/bold blue]\")\n",
    "\n",
    "# Create inference engine with the best model\n",
    "gec_inference = GECInference(\n",
    "    model_path=\"./models/contrastive_model\",  # Use contrastive model\n",
    "    model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "console.print(\"[green]‚úÖ Inference engine ready![/green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing\n",
    "console.print(\"[bold blue]üéÆ Interactive Testing[/bold blue]\")\n",
    "\n",
    "# Test samples\n",
    "test_sentences = [\n",
    "    \"T√¥i ƒëang h·ªçc ti·∫øng vi·ªát ·ªü tr∆∞·ªùng ƒë·∫°i h·ªçc.\",\n",
    "    \"H√¥m nay tr·ªùi r·∫•t ƒë·∫πp v√† t√¥i mu·ªën ƒëi ch∆°i.\",\n",
    "    \"C√¥ ·∫•y l√†m vi·ªác t·∫°i m·ªôt c√¥ng ty l·ªõn ·ªü H√† N·ªôi.\",\n",
    "    \"Ch√∫ng t√¥i s·∫Ω ƒëi du l·ªãch v√†o cu·ªëi tu·∫ßn n√†y.\"\n",
    "]\n",
    "\n",
    "console.print(\"\\n[yellow]üìù Test Results:[/yellow]\")\n",
    "for i, sentence in enumerate(test_sentences, 1):\n",
    "    corrected = gec_inference.correct_text(sentence)\n",
    "    console.print(f\"\\n{i}. Original: {sentence}\")\n",
    "    console.print(f\"   Corrected: {corrected}\")\n",
    "\n",
    "# Custom input\n",
    "console.print(\"\\n[bold cyan]‚úèÔ∏è Try your own text:[/bold cyan]\")\n",
    "print(\"Enter Vietnamese text to correct (or 'quit' to exit):\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"> \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    \n",
    "    corrected = gec_inference.correct_text(user_input)\n",
    "    print(f\"Corrected: {corrected}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "from evaluator import F05Evaluator\n",
    "\n",
    "console.print(\"[bold blue]üìä Evaluating on Test Set...[/bold blue]\")\n",
    "\n",
    "# Create evaluator\n",
    "evaluator = F05Evaluator()\n",
    "\n",
    "# Evaluate on test set (using subset for faster evaluation)\n",
    "test_data = data['test'][:100]  # Use 100 samples for evaluation\n",
    "sources = [item['source'] for item in test_data]\n",
    "references = [item['target'] for item in test_data]\n",
    "\n",
    "# Generate predictions\n",
    "console.print(\"[yellow]üîÆ Generating predictions...[/yellow]\")\n",
    "predictions = []\n",
    "for source in sources:\n",
    "    pred = gec_inference.correct_text(source)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Calculate metrics\n",
    "results = evaluator.evaluate_batch(predictions, references, sources)\n",
    "\n",
    "console.print(\"\\n[bold green]üìà Evaluation Results:[/bold green]\")\n",
    "for metric, value in results.items():\n",
    "    if isinstance(value, float):\n",
    "        console.print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        console.print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b2389",
   "metadata": {},
   "source": [
    "## üíæ Step 8: Save and Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db60851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and create export package\n",
    "import json\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "console.print(\"[bold blue]üíæ Saving Results and Creating Export Package...[/bold blue]\")\n",
    "\n",
    "# Create results summary\n",
    "results_summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"training_config\": TRAINING_CONFIG,\n",
    "    \"evaluation_results\": results,\n",
    "    \"test_samples\": len(test_data),\n",
    "    \"model_paths\": {\n",
    "        \"base_model\": TRAINING_CONFIG[\"output_dir\"],\n",
    "        \"contrastive_model\": \"./models/contrastive_model\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results\n",
    "with open(\"./results_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "console.print(\"[green]‚úÖ Results saved to ./results_summary.json[/green]\")\n",
    "\n",
    "# Create downloadable package\n",
    "console.print(\"[yellow]üì¶ Creating export package...[/yellow]\")\n",
    "\n",
    "with zipfile.ZipFile(\"vietnamese_gec_models.zip\", \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Add results\n",
    "    zipf.write(\"results_summary.json\")\n",
    "    \n",
    "    # Add model files (if they exist)\n",
    "    import glob\n",
    "    for model_file in glob.glob(\"./models/**/*.bin\", recursive=True):\n",
    "        zipf.write(model_file)\n",
    "    for config_file in glob.glob(\"./models/**/config.json\", recursive=True):\n",
    "        zipf.write(config_file)\n",
    "    \n",
    "    # Add data samples\n",
    "    if os.path.exists(\"./data/contrastive_train.json\"):\n",
    "        zipf.write(\"./data/contrastive_train.json\")\n",
    "\n",
    "console.print(\"[bold green]üéâ Export package created: vietnamese_gec_models.zip[/bold green]\")\n",
    "console.print(\"[blue]üìÅ You can download this file from the Colab file browser[/blue]\")\n",
    "\n",
    "# Display final summary\n",
    "console.print(\"\\n[bold cyan]üèÜ Training Pipeline Completed Successfully![/bold cyan]\")\n",
    "console.print(f\"[green]‚úÖ Base model trained and saved[/green]\")\n",
    "console.print(f\"[green]‚úÖ Contrastive learning applied[/green]\")\n",
    "console.print(f\"[green]‚úÖ Model evaluated on test set[/green]\")\n",
    "console.print(f\"[green]‚úÖ Results exported for download[/green]\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
